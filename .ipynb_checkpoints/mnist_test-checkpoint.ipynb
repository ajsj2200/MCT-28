{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Flatten, Dropout, BatchNormalization, Reshape, LeakyReLU, Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(x_train.reshape(60000, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_3 = x_train[y_train  == 3]\n",
    "y_3 = y_train[y_train == 3]\n",
    "y_3 = pd.Series(y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_7 = x_train[y_train == 7][:10]\n",
    "y_7 = y_train[y_train == 7][:10]\n",
    "y_7 = pd.Series(y_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.DataFrame(x_3).reset_index(drop=True) / 127.5 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6129</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6130</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6131 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    ...  774  775  776  \\\n",
       "0    -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "1    -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "2    -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "3    -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "4    -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "6126 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "6127 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "6128 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "6129 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "6130 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "\n",
       "      777  778  779  780  781  782  783  \n",
       "0    -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "1    -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "2    -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "3    -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "4    -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "6126 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "6127 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "6128 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "6129 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "6130 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "\n",
       "[6131 rows x 784 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5173</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6131 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    ...  774  775  776  \\\n",
       "4408 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "3299 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "1499 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "1707 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "1737 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1639 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "901  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "2621 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "777  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "5173 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0 -1.0 -1.0   \n",
       "\n",
       "      777  778  779  780  781  782  783  \n",
       "4408 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "3299 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "1499 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "1707 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "1737 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "1639 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "901  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "2621 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "777  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "5173 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
       "\n",
       "[6131 rows x 784 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled=x_data.sample(frac=1)\n",
    "df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_shuffled.values.reshape(6131, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(28, 28, 1))\n",
    "\n",
    "# 28 X 28\n",
    "x = Conv2D(32, 3, padding='same')(encoder_input) \n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x) \n",
    "\n",
    "# 28 X 28 -> 14 X 14\n",
    "x = Conv2D(64, 3, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = LeakyReLU()(x) \n",
    "\n",
    "# 14 X 14 -> 7 X 7\n",
    "x = Conv2D(64, 3, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "# 17 X 7\n",
    "x = Conv2D(64, 3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(1, 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# 2D 좌표로 표기하기 위하여 2를 출력값으로 지정합니다.\n",
    "x = Conv2DTranspose(64, 3, strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "# 7 X 7 -> 14 X 14\n",
    "x = Conv2DTranspose(64, 3, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "# 14 X 14 -> 28 X 28\n",
    "x = Conv2DTranspose(64, 3, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "# 28 X 28 -> 28 X 28\n",
    "x = Conv2DTranspose(32, 3, strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "# 최종 output\n",
    "decoder_output = Conv2DTranspose(1, 3, strides=1, padding='same', activation='tanh')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 1)           65        \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 1)           4         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 7, 7, 64)          640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 187,782\n",
      "Trainable params: 186,884\n",
      "Non-trainable params: 898\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae = Model(encoder_input, decoder_output)\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 1)           65        \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 1)           4         \n",
      "=================================================================\n",
      "Total params: 93,637\n",
      "Trainable params: 93,187\n",
      "Non-trainable params: 450\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Model(inputs=ae.inputs, outputs=ae.layers[14].output)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv2d/Conv2D (defined at <ipython-input-15-cd8a1f7fe6b7>:1) ]] [Op:__inference_train_function_3483]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-1297a731909d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m ae.fit(df, df, \n\u001b[0m\u001b[0;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ttttf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ttttf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ttttf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ttttf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ttttf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ttttf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ttttf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ttttf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ttttf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv2d/Conv2D (defined at <ipython-input-15-cd8a1f7fe6b7>:1) ]] [Op:__inference_train_function_3483]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "ae.fit(df, df, \n",
    "                 batch_size=16, \n",
    "                 epochs=100,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = ae.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = predict.reshape(6141, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047761383759586246"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(df.reshape(6141, 784), predict.reshape(6141, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_loss = tf.keras.losses.mae(predict.reshape(6141, 784), df.reshape(6141, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(train_loss).hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>0.127050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>0.123493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>0.133958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "2925  0.127050\n",
       "4860  0.123493\n",
       "5984  0.133958"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[tmp.values > 0.12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24053306610>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAObklEQVR4nO3de4xc9XnG8efBGBsMFjgUyxhzcyCVExIDiwmXAhUqAVTJ0LQIpBIH0SwKcUtUVJWkUgGpSmmaS5uGRDXgxkGUBJW4WC1JYzZpKCFxvQYDxhBuMcXG2LFdagg3X97+sQe0wJ7fLnP3vt+PNJqZ886Z83rkZ8/M+Z2ZnyNCAMa/vbrdAIDOIOxAEoQdSIKwA0kQdiCJvTu5sX08KSZrSic3CaTymn6tN+J1j1RrKuy2z5X095ImSLo5Im4oPX6ypuhkn93MJgEUrIiB2lrDb+NtT5B0o6TzJM2RdIntOY0+H4D2auYz+zxJT0XEMxHxhqTvSJrfmrYAtFozYZ8p6blh99dXy97Gdr/tQduDO/R6E5sD0Iy2H42PiEUR0RcRfRM1qd2bA1CjmbBvkDRr2P3DqmUAelAzYV8p6RjbR9neR9LFkpa1pi0Ardbw0FtE7LS9UNJ/aGjobXFEPNqyzgC0VFPj7BFxt6S7W9QLgDbidFkgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkujolM1oj/WfO7W2tnrhP7R32ztfLdaXv3Jsbe2yqc/V1iRpzk8uL9aPnr6lWJ9w4fba2q7t9bXxij07kARhB5Ig7EAShB1IgrADSRB2IAnCDiThiOjYxqZ6Wpzsszu2vSxOfHB3be3aQ1a1ddt7jbK/2K363tq97Y/8bEFtbdbvr2l1Oz1hRQxoe2zzSLWmTqqxvU7SS5J2SdoZEX3NPB+A9mnFGXS/HRHlU5kAdB2f2YEkmg17SPqh7VW2+0d6gO1+24O2B3fo9SY3B6BRzb6NPz0iNtg+RNJy249HxL3DHxARiyQtkoYO0DW5PQANamrPHhEbquvNkpZKmteKpgC0XsNhtz3F9gFv3pZ0jqTxOZ4BjAPNvI2fLmmp7Tef558j4gct6Qpvs/nK+u+rS9L1h9R/Z719o9xDvrDluGL93577UMPPfeeHFxfrMybsW6z/60n/WFtbeOqVxXV9/0PF+p6o4bBHxDOSPtLCXgC0EUNvQBKEHUiCsANJEHYgCcIOJMFPSe8BZnz38WL92k8dX1u7Y+2JxXWPvb7Jn1Te+r/F8rStTzT81J8++g+L9Sf+6sBifc2ZN9XWdkzdp7huubpnYs8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzr4H2LV1W7G+6vj6v9mz9WD5uRvqaOz2nnlobS3236+47p/evbRYP3vfcvcLN5xeW9vnByuL645H7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2ceBCR/8QG3t8SsOLK477aHy3/uXP/ZyIy295cOHPl9bu/Wou5p67r/ZOqdYf+iv59bW9tOKpra9J2LPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+Dly97F9qa6dPfq288seb2/Zeo+wvdjcxafSc7/5xsf6bX3+hWN/vmXxj6SWj7tltL7a92faaYcum2V5u+8nq+qD2tgmgWWN5G/8tSee+Y9k1kgYi4hhJA9V9AD1s1LBHxL2S3vm7SPMlLaluL5F0QWvbAtBqjX5mnx4RG6vbL0iaXvdA2/2S+iVpssq/OQagfZo+Gh8RISkK9UUR0RcRfRM1qdnNAWhQo2HfZHuGJFXXm1vXEoB2aDTsyyQtqG4vkNTcdxUBtN2on9lt3y7pLEkH214v6VpJN0i6w/blkp6VdFE7m0TZGZPfqK01PsrdGuc/Vj+Qv+mew4rrHvFA/b9LknY+s66RltIaNewRcUlN6ewW9wKgjThdFkiCsANJEHYgCcIOJEHYgST4ius48LszT6ytvXjpKcV1/+/9bmrbM07dUKxfP7v+FIyrTrm4uO7kfypPVd3u6abHG/bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+zj3IG3/qxcb/P2//K8T9XWfn7zN4rr/ta5f1KsH/zTKcX6rqd+Waxnw54dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnB1ttd9/P11b+7ttc4rr/tcXvlasn/DzTxbrR3xudm1t1xP1fY1X7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2dFWu7bW//b79685q7juhd9YXayv/ui3i/VTzlxYW3sf4+zvZnux7c221wxbdp3tDbZXV5fz29smgGaN5W38tySdO8Lyr0bE3Opyd2vbAtBqo4Y9Iu6VVJ6HB0DPa+YA3ULbD1dv8w+qe5DtftuDtgd36PUmNgegGY2G/ZuSZkuaK2mjpC/XPTAiFkVEX0T0TdSkBjcHoFkNhT0iNkXErojYLekmSfNa2xaAVmso7LZnDLt7oaQ1dY8F0BtGHWe3fbuksyQdbHu9pGslnWV7rqSQtE7SFe1rEePVpH9fWax//MY/K9ZXX/X1Yv2cK39aW3vwtv2L6+5+5ZVifU80atgj4pIRFt/Shl4AtBGnywJJEHYgCcIOJEHYgSQIO5AEX3FFzzr0i/cX6wP95TMyzzjgF7W11UfOL2987RPl+h6IPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4O/ZYE7y7WB/89dH1xU1bWtxN72PPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJpBlnn/D+o4r19V+aXKy/8VDtDFea+ZPytFZ7/2hVsY7GDGz/YLH+4s79amulqaTHK/bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEmnH2F0+cXqyvOunG8hOcVF/q/9hZxVXvv+eUYn32rb8qb3s0W+rHjHt5PHnC1KnF+pbfK4+j7+X7ynXFe+5pPBt1z257lu0f215r+1HbV1XLp9lebvvJ6rr+rBMAXTeWt/E7JV0dEXMkfVTSZ2zPkXSNpIGIOEbSQHUfQI8aNewRsTEiHqhuvyTpMUkzJc2XtKR62BJJF7SpRwAt8J4+s9s+UtLxklZImh4RG6vSC5JG/FBsu19SvyRNVv25ygDaa8xH423vL+lOSZ+NiO3DaxER0shHQyJiUUT0RUTfRJUn4gPQPmMKu+2JGgr6bRHxvWrxJtszqvoMSZvb0yKAVhj1bbxtS7pF0mMR8ZVhpWWSFki6obq+qy0dtsjOT2wt1ner/LPEJYtm/Wf5uS/7UfkJLmt405Kkv916XG1t2XP1NUna8vS0Yv3w75dfl+fPLP8XOvC4+p9snnfI/xTXXXro14r1vUbZV53x8EW1tal6urjueDSWz+ynSbpU0iO2V1fLPq+hkN9h+3JJz0qqf2UBdN2oYY+I+yS5pnx2a9sB0C6cLgskQdiBJAg7kARhB5Ig7EASHjr5rTOmelqc7O4cwH/1gnnl+h+92PBz33/87cV6M2P4Y1Eab+7mttu9/RNuvKpYP3LJutrazg3Pt7ib3rAiBrQ9to04esaeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSSDPO3k4Tjp1drL92+IHF+i//oPw397TjnizWD9+3/ueirz2kvdNFjzbOPvBq/U+RfXrgE8V1P3Dza8V6rHykWM+IcXYAhB3IgrADSRB2IAnCDiRB2IEkCDuQBOPswDjCODsAwg5kQdiBJAg7kARhB5Ig7EAShB1IYtSw255l+8e219p+1PZV1fLrbG+wvbq6nN/+dgE0aizzs++UdHVEPGD7AEmrbC+val+NiC+1rz0ArTKW+dk3StpY3X7J9mOSZra7MQCt9Z4+s9s+UtLxklZUixbaftj2YtsH1azTb3vQ9uAOvd5ctwAaNuaw295f0p2SPhsR2yV9U9JsSXM1tOf/8kjrRcSiiOiLiL6JmtR8xwAaMqaw256ooaDfFhHfk6SI2BQRuyJit6SbJJVnTgTQVWM5Gm9Jt0h6LCK+Mmz5jGEPu1DSmta3B6BVxnI0/jRJl0p6xPbqatnnJV1ie66kkLRO0hVt6A9Ai4zlaPx9kkb6fuzdrW8HQLtwBh2QBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJjk7ZbPtXkp4dtuhgSVs61sB706u99WpfEr01qpW9HRERvzFSoaNhf9fG7cGI6OtaAwW92luv9iXRW6M61Rtv44EkCDuQRLfDvqjL2y/p1d56tS+J3hrVkd66+pkdQOd0e88OoEMIO5BEV8Ju+1zbv7D9lO1rutFDHdvrbD9STUM92OVeFtvebHvNsGXTbC+3/WR1PeIce13qrSem8S5MM97V167b0593/DO77QmSnpD0O5LWS1op6ZKIWNvRRmrYXiepLyK6fgKG7TMkvSzp2xHxoWrZFyVti4gbqj+UB0XEn/dIb9dJernb03hXsxXNGD7NuKQLJH1SXXztCn1dpA68bt3Ys8+T9FREPBMRb0j6jqT5Xeij50XEvZK2vWPxfElLqttLNPSfpeNqeusJEbExIh6obr8k6c1pxrv62hX66ohuhH2mpOeG3V+v3prvPST90PYq2/3dbmYE0yNiY3X7BUnTu9nMCEadxruT3jHNeM+8do1Mf94sDtC92+kRcYKk8yR9pnq72pNi6DNYL42djmka704ZYZrxt3TztWt0+vNmdSPsGyTNGnb/sGpZT4iIDdX1ZklL1XtTUW96cwbd6npzl/t5Sy9N4z3SNOPqgdeum9OfdyPsKyUdY/so2/tIuljSsi708S62p1QHTmR7iqRz1HtTUS+TtKC6vUDSXV3s5W16ZRrvumnG1eXXruvTn0dExy+SztfQEfmnJf1FN3qo6etoSQ9Vl0e73Zuk2zX0tm6Hho5tXC7pfZIGJD0p6R5J03qot1slPSLpYQ0Fa0aXejtdQ2/RH5a0urqc3+3XrtBXR143TpcFkuAAHZAEYQeSIOxAEoQdSIKwA0kQdiAJwg4k8f8yZlRbOhZkVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(df[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_shuffled[df_shuffled['Y'] == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23ffe811580>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp.iloc[0, :-1]\n",
    "plt.imshow(tmp.iloc[0, :-1].values.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23ffea4ac10>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ae.predict(tmp.iloc[0, :-1].values.reshape(1, 28, 28, 1)).reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "forclust = model2.predict(df).reshape(6141, 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(forclust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3342\n",
       "0    2799\n",
       "dtype: int64"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(kmeans.labels_).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = DBSCAN(eps=10, min_samples=10).fit(forclust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6141\n",
       "dtype: int64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clustering.labels_).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.cluster.k_means_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-257-d0b820332b4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mspherecluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSphericalKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mskm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSphericalKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mskm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforclust\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ttttf\\lib\\site-packages\\spherecluster\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mspherical_kmeans\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSphericalKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvon_mises_fisher_mixture\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVonMisesFisherMixture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msample_vMF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ttttf\\lib\\site-packages\\spherecluster\\spherical_kmeans.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m from sklearn.cluster.k_means_ import (\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0m_init_centroids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cluster.k_means_'"
     ]
    }
   ],
   "source": [
    "from spherecluster import SphericalKMeans\n",
    "skm = SphericalKMeans(n_clusters=3)\n",
    "skm.fit(forclust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
